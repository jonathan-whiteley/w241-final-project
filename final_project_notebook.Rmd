---
title: "Analysis of Experiment Data"
author: "Jonathan, Aysun, Isabel"
date: '2022-04-06'
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(data.table)
library(sandwich)
library(lmtest)
library(stargazer)

library(ggplot2)
library(knitr)
library(tidyr)

```

```{r load data, include = FALSE}
d <- fread("data/w241_survey_final_4_2_22.csv")
```

```{r, include = TRUE}
head(d)
```
# EDA

First, we are going to rename some variables to make them more readable.

```{r variable_names, include=TRUE}
setnames(
  x = d,
  old = c("Duration (in seconds)","Gender Q", "Age Q", "Income Q", "Deceased of Cancer Q", "Previous Donation Q",    "Q8_1", "GROUP"),
  new = c(             "duration",  "gender",   "age",   "income",      "deceased_cancer",   "previous_donation", "outcome", "group")
)
```

## General statistics and null values

We can get an idea of the values in the table with a summary of the statistics for each column. 

```{r data_summary, include=TRUE}
summary(d)
```

```{r data_summary, include=TRUE}
summary(d$outcome)
```

No null values in the outcome variable `outcome` (the issue observed in the pilot study is solved)

## Number of surveys

```{r EDA, include = TRUE}
total_surveys <- d[ , .N]
total_surveys
```

We collected `r total_surveys` `r total_surveys` data points during pilot. Subjects are well distributed across groups.

```{r EDA, include = TRUE}
d[ , .N, by=group]
```

# Average treatment effect (ATE)

Let's calculate the value of the outcome variable in each group.
```{r EDA, include = TRUE}
pilot_group_mean <- d[ , .(mean_donate = mean(outcome, na.rm = T)), by=group]
pilot_group_mean
```
The average willingness to donate in the control group is lower than in the treatment groups. The charts below show the distribution of the outcome variable (i.e. willingness to donate which take values 0-10). We also plot the distribution of the outcome variable by treatment and control groups as well as box plots that show and compare the distribution of the outcomes for different treatment groups. Overall, we have seensome increase in outcome for treatment groups but the distirbution is much more dispersed than the control group.

```{r}
hist(
  d$outcome, 
  col = 'steelblue', 
  xlab = 'Willingness to Donate', 
  main = 'Distribution of Outcome Variable'
  )
```


```{r}
d %>%
  ggplot() +
  aes(x=outcome, fill = group) +
  geom_bar(position='dodge') +
  labs(
    title = 'Distribution of Outcome Variable for each group', 
    x = 'Willingness to Donate (0-10)'
  ) 

d %>%
  ggplot() +
  aes(x=outcome, y=group) + 
  geom_boxplot() + 
  labs (
    title = 'Distribution of Outcome Variable of Each Group',
    x = 'Willingness to Donate (0-10)',
    y = 'Groups'
  )
```

```{r boxplot + stripchart}
#install.packages("beeswarm")
#library(beeswarm)

# d[ , beeswarm(outcome ~ group,
#          pch = 19, 
#          col = c("#FFE099" , "#F76D5E", "#3FA0FF" ))]

# Boxplot first, labels go here
d[ , boxplot(outcome ~ group, col = "white",
             names = c("Control", "Negative Treatment", "Positive Treatment"),
             ylab = "Willingness to Donate",
             xlab = "Group")]

# Points
d[ , stripchart(outcome ~ group,
           method = "jitter",
           pch = 19,
           col = c("#66c2a5" , "#fc8d62", "#8da0cb" ),     #color-blind safe colors
           vertical = TRUE,
           add = TRUE)]



```

But, how big is the effect size?

```{r ate, include = TRUE }
positive_outcome <- d[group=="TREAT_POS", mean(outcome, na.rm = T) ]
negative_outcome <- d[group=="TREAT_NEG", mean(outcome, na.rm = T) ]
baseline <- d[group=="CONTROL", mean(outcome, na.rm = T) ]

ate_positive <- positive_outcome - baseline
ate_positive

ate_negative <- negative_outcome - baseline
ate_negative

```

The average treatment effect for the positive message is `ate_positive` `r ate_positive`, and the average treatment effect of the negative message is `ate_negative` `r ate_negative`.

```{r ate_regression, include = TRUE }
basic_mod <- d[ , lm(outcome ~ group)]
se.basic_mod <- coeftest(basic_mod, vcov = vcovHC)[ , "Std. Error"]
full_mod_nohte <- d[ , lm(outcome ~ group + deceased_cancer + previous_donation)] ## other covariates: "gender", "age", "income"
se.full_mod_nohte <- coeftest(full_mod_nohte, vcov = vcovHC)[ , "Std. Error"]

d[ , high_income := ifelse(income =="Above $150,000","Yes","No")]

full_mod_hte <- d[ , lm(outcome ~ group + high_income + group * high_income + deceased_cancer + previous_donation)] 
se.full_mod_hte <- coeftest(full_mod_hte, vcov = vcovHC)[ , "Std. Error"]

stargazer(basic_mod, full_mod_nohte, full_mod_hte, type = "text", se = list(se.basic_mod, se.full_mod_nohte, se.full_mod_hte), star.cutoffs = c(0.05, 0.01, 0.001), title = "Table 1: The Effect of Framing on Intent to Donate") #for report

stargazer(basic_mod, full_mod_nohte, type = "text", se = list(se.basic_mod, se.full_mod_nohte), star.cutoffs = c(0.05, 0.01, 0.001), title = "Table 1: The Effect of Framing on Intent to Donate") #for presentation

```

We also ran regression to understand ATEs and whether they're statistically significant. Not to our surprise, they are not. We also added two covariates (previous donation and people who lost family member or close friend to cancer) in the full model that we think would explain the outcome variable to reduce the standard errors, but treatments are still not statistically significant. Though, it's important to note that previous donation explains the outcome variable in a statistically significant way. 

We also had a hypothesis that people with high income (we defined that as people with $150K+ household income) might have different treatment effects compared to others. We didn't see that's the case as a result of the regression analysis above (column 3).

# Covariate analysis

Let's do a covariate check to ensure that random assignment is working properly. In this study we are measuring five covariates:
- `gender`: Gender identity using four categories
- `age`: Age group using six categories
- `income`: Personal income using five categories 
- `deceased_cancer`: Family member or close friend who died from cancer: Yes/No
- `previous_donation`: Previous donations to charitable organizations: Yes/No

## Gender
```{r gender_covariate, include=TRUE}
gender_check <- d[, .N ,by=.(group, gender)]
gender_check <- gender_check[order(group, gender)]
gender_check

d[group %in% c('CONTROL','TREAT_NEG')  , wilcox.test(as.numeric(as.factor(gender)) ~ group)]

d[group %in% c('CONTROL','TREAT_POS')  , wilcox.test(as.numeric(as.factor(gender)) ~ group)]
```

```{r gender_covariate, include=TRUE}
d %>%
  ggplot() +
  aes(x=gender, fill = group) +
  geom_bar(position='dodge') +
  labs(
      title = 'Distribution of gender across groups', 
      x = 'Gender'
  ) 
```

The gender seems to be balanced across groups. We also ran a wilcox.test to compare gender distribution for among each test group and control group. Both tests give high p-values that suggest we cannot reject the null hypothesis that among test and control groups, gender distribution is the same.

## Age

```{r age_covariate, include=TRUE}
age_check <- d[, .N ,by=.(group, age)]
age_check <- age_check[order(group, age)]
age_check

d[group %in% c('CONTROL','TREAT_NEG')  , wilcox.test(as.numeric(as.factor(age)) ~ group)]

d[group %in% c('CONTROL','TREAT_POS')  , wilcox.test(as.numeric(as.factor(age)) ~ group)]
```
```{r age_covariate, include=TRUE}
d %>%
  ggplot() +
  aes(x=age, fill = group) +
  geom_bar(position='dodge') +
  labs(
      title = 'Distribution of age across groups', 
      x = 'Age group'
  ) 
```
The distribution plot does not show any big difference in age distribution between groups. We also ran a wilcox.test to compare age distribution for among each test group and control group. Both tests give high p-values that suggest we cannot reject the null hypothesis that among test and control groups, age distribution is the same.

## Income

```{r income_covariate, include=TRUE}
income_check <- d[, .N ,by=.(group, income)]
income_check <- income_check[order(group, income)]
income_check

d[group %in% c('CONTROL','TREAT_NEG')  , wilcox.test(as.numeric(as.factor(income)) ~ group)]

d[group %in% c('CONTROL','TREAT_POS')  , wilcox.test(as.numeric(as.factor(income)) ~ group)]
```
```{r income_covariate, include=TRUE}
d %>%
  ggplot() +
  aes(x=income, fill = group) +
  geom_bar(position='dodge') +
  labs(
      title = 'Distribution of income across groups', 
      x = 'Income group'
  ) 
```

The distribution plot shows that age groups are similar across treatment and control groups. We also ran a wilcox.test to compare income distribution for among each test group and control group. Both tests give high p-values that suggest we cannot reject the null hypothesis that among test and control groups, income distribution is the same.

## Relative/Friend who died from cancer

```{r deceased_covariate, include=TRUE}
deceased_check <- d[, .N ,by=.(group, deceased_cancer)]
deceased_check

d[group %in% c('CONTROL','TREAT_NEG')  , wilcox.test(as.numeric(as.factor(deceased_cancer)) ~ group)]

d[group %in% c('CONTROL','TREAT_POS')  , wilcox.test(as.numeric(as.factor(deceased_cancer)) ~ group)]
```
```{r deceased_covariate, include=TRUE}
d %>%
  ggplot() +
  aes(x=deceased_cancer, fill = group) +
  geom_bar(position='dodge') +
  labs(
      title = 'Distribution of relative/friend who died from cancer across groups', 
      x = 'Relative/friend who died from cancer'
  ) 
```
In general, we observe balance across groups in the number of relatives or friends who died from cancer. We also ran the wilcox.test to compare relatives who died from cancer distribution for among each test group and control group. The test shows a significant difference between the negative treatment and the control group. However, this could be just by chance.

## Previous donation

```{r prev_donation_covariate, include=TRUE}
prev_donation_check <- d[, .N ,by=.(group, previous_donation)]
prev_donation_check <- prev_donation_check[order(group)]
prev_donation_check

d[group %in% c('CONTROL','TREAT_NEG')  , wilcox.test(as.numeric(as.factor(previous_donation)) ~ group)]

d[group %in% c('CONTROL','TREAT_POS')  , wilcox.test(as.numeric(as.factor(previous_donation)) ~ group)]
```

```{r prev_donation_covariate, include=TRUE}
d %>%
  ggplot() +
  aes(x=previous_donation, fill = group) +
  geom_bar(position='dodge') +
  labs(
      title = 'Distribution of previous donations across groups', 
      x = 'Previous donations to charitable organizations'
  ) 
```
The distribution plot shows about the same distribution in the previous donation variable across groups. We also ran a wilcox.test on previous donation among each test group and control group. Both tests give high p-values that suggest we cannot reject the null hypothesis that among test and control groups, previous donation distribution is the same.

```{r overall_covariate_balance_check, include=TRUE}
null_mod <- d[ , lm (as.numeric(as.factor(group)) ~ 1)]
full_mod <- d[ , lm (as.numeric(as.factor(group)) ~ 1 + gender + age + income + deceased_cancer + previous_donation)]
anova_mod <- anova(full_mod, null_mod, test = 'F')
anova_mod

```
Since we ran multiple comparison tests for each covariate separately, we might run into a false positive as a result of possible fishing expedition here (i.e. green jelly beans problem covered in the class). A more robust way of understanding whether we have covariance balance check is understanding if covariates explain the treatment assignments with an F-test. Since our F-test output is  giving us a very high p-value, we cannot reject the null hypothesis that all these covariates are not explaining the treatment assignment. So, randomization seems not showing an issue here.

# Other variables

During the survey other interesting variables are captured, such as the time it took for the participants to answer the survey and if the survey was finished or not. 

## Survey duration

```{r survey_duration, include=TRUE}
d[, .(mean_survey_duration = mean(duration), 
      min_survey_duration = min(duration), 
      max_survey_duration = max(duration)
      ) ,by=.(group)]
```

Since the control group does not have to read the treatment message, the average time participants spend filling the survey is less. Positive treatment and negative treatment groups spend about the same time completing the survey. The timer implemented as a result of the pilot study results seems to be working. 

## Finished survey

```{r finished_survey, include=TRUE}
d[, .(fraction_finished = mean(Finished)),by=.(group)]
```
 All subjects finished the survey.
 
# Power Analysis

In this section we conduct a power analysis to check how many participants we need in the experiment to have enough power to detect an effect.

```{r power_analysis, include=TRUE} 
number_of_subjects <- seq(10, 2000, by=50) 

# create a function to repeat to process to calculate power
power_function <- function(sample_size=10, treatment_group="TREAT_NEG"){
  
  p_values <- rep(NA, 1000) 

  for(i in 1:1000) {
    experiment <- d[ (group == "CONTROL" | group== treatment_group) & !is.na(outcome) , 
                     .SD[sample(.N, sample_size/2 , replace=TRUE)], by=group ] 
    t_test <- t.test(experiment[group==treatment_group, outcome], experiment[group=="CONTROL",outcome]) 
    p_values[i] <- t_test$p.value
  }
  
  exp_power = mean(p_values < 0.05)
  
  return(exp_power)
}

```

```{r power_analysis, include=TRUE}
# power analysis for positive treatment

power_with_size_pos_treatment <- NA 

for(i in 1:length(number_of_subjects)) { 
  power_with_size_pos_treatment[i] <- power_function(sample_size = number_of_subjects[i], treatment_group="TREAT_POS" )
}

plot(x = number_of_subjects, y = power_with_size_pos_treatment, type = 'l', 
     main='Power Analysis for Positive Treatment', xlab='Number of Subjects', ylab='Power')

```


```{r power_analysis, include=TRUE}

# power analysis for negative treatment

power_with_size_neg_treatment <- NA 

for(i in 1:length(number_of_subjects)) { 
  power_with_size_neg_treatment[i] <- power_function(sample_size = number_of_subjects[i], treatment_group="TREAT_NEG" )
}

plot(x = number_of_subjects, y = power_with_size_neg_treatment, type = 'l', 
     main='Power Analysis for Negative Treatment', xlab='Number of Subjects', ylab='Power')
```

The treatment effect in the main experiment is between 1/3 and 1/4 of the treatment effect we observed during the pilot data. As a consequence, even though we were very conservative and included a lot more subjects in the experiment than the power analysis of the pilot data suggested, we do not have enough power to detect an effect. 
 
 